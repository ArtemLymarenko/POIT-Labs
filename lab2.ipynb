{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**1. Визначити сутність і виконати аналіз функцій парного блокуючого обміну.**\n",
    "\n",
    "Парний блокуючий обмін - це базова модель взаємодії двох процесів у MPI, коли один процес надсилає повідомлення, а інший його приймає, і обидві операції є блокуючими, тобто процес зупиняється, доки виклик не завершиться.\n",
    "\n",
    "У парному обміні беруть участь два процеси: відправник і одержувач.\n",
    "\n",
    "Відправник викликає функцію MPI_Send, передаючи адресу буфера, тип даних, кількість елементів, тег повідомлення та ранг процесу-одержувача.\n",
    "\n",
    "Одержувач викликає MPI_Recv з аналогічними параметрами, вказуючи, від кого він чекає повідомлення та який тип і тег має відповідати.\n",
    "\n",
    "Блокуюча відправка означає, що процес-відправник не продовжить виконання, поки MPI не буде повністю впевнена, що параметри буфера можна безпечно змінювати - або тому, що дані вже гарантовано передані, або тому, що вони скопійовані у внутрішній буфер MPI.\n",
    "\n",
    "Важливою частиною парного обміну є узгодженість параметрів: обидві сторони мають співпасти за типом даних, розміром та тегом. Це забезпечує коректність і запобігає неоднозначності.\n",
    "\n",
    "Блокуючі виклики забезпечують ряд важливих властивостей.\n",
    " * Кожен MPI_Recv отримає саме те повідомлення, якого він очікує.\n",
    " * Вони забезпечують локальну синхронізацію між процесами. Хоча MPI_Send не зобов’язаний чекати фактичного прийому, у більшості реалізацій прості повідомлення передаються одразу, і відправник блокується тільки до моменту копіювання в буфер MPI.\n",
    " * Парний блокуючий обмін може бути джерелом взаємних блокувань (deadlock), якщо обидва процеси викликають MPI_Send, не маючи активних прийомів. Наприклад, двостороння відправка без попереднього MPI_Recv може заблокувати програму, якщо реалізація MPI не має достатньо буфера для обох повідомлень.\n",
    " * Також, важливо розуміти його семантику: завершення відправки не означає, що повідомлення доставлене одержувачу. Завершення прийому означає, що дані гарантовано знаходяться у буфері одержувача."
   ],
   "id": "96a916e4d2a4ec9a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T12:28:55.446487Z",
     "start_time": "2025-11-22T12:28:53.956041Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install mpi4py",
   "id": "a635142cc0110897",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpi4py in c:\\users\\artem\\pycharmprojects\\pythonproject\\distibutedcalculations\\jupyterproject\\.venv\\lib\\site-packages (4.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Тестова програма для перевірки роботи бібліотеки в середовищі Jupiter Notebook**",
   "id": "18ad33120ac6bc52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T12:28:55.472526Z",
     "start_time": "2025-11-22T12:28:55.467444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile test_mpi.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "print(f\"Rank: {comm.Get_rank()} | Size: {comm.Get_size()}\")"
   ],
   "id": "99e1330e475e7f46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_mpi.py\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T12:28:55.806907Z",
     "start_time": "2025-11-22T12:28:55.566799Z"
    }
   },
   "cell_type": "code",
   "source": "!mpiexec -n 4 python test_mpi.py",
   "id": "4f03dc2a3773d2e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1 | Size: 4\n",
      "Rank: 0 | Size: 4\n",
      "\n",
      "\n",
      "Rank: 2 | Size: 4\n",
      "Rank: 3 | Size: 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**2. Побудувати програму-шаблон для парного блокуючого обміну**",
   "id": "8a02bd4094765079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T12:28:55.829430Z",
     "start_time": "2025-11-22T12:28:55.824657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile task2.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "# function to return whether a number of a process is odd or even\n",
    "def odd(number):\n",
    "    if (number % 2) == 0:\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            #number of the process running the code\"\n",
    "    numProcesses = comm.Get_size()  #total number of processes running\"\n",
    "    myHostName = MPI.Get_processor_name()  #machine name running the code\"\n",
    "\n",
    "    # num of processes must be even\n",
    "    if numProcesses > 1 and not odd(numProcesses):\n",
    "        sendValue = id\n",
    "\n",
    "         #odd processes receive from their paired 'neighbor', then send\n",
    "        if odd(id):\n",
    "            comm.send(sendValue, dest=id - 1)\n",
    "            receivedValue = comm.recv(source=id - 1)\n",
    "\n",
    "        #even processes receive from their paired 'neighbor', then send\n",
    "        else:\n",
    "            receivedValue = comm.recv(source=id + 1)\n",
    "            comm.send(sendValue, dest=id + 1)\n",
    "\n",
    "        print(\n",
    "            \"Process {} of {} on {} computed {} and received {}\".format(\n",
    "                id, numProcesses, myHostName, sendValue, receivedValue\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if id == 0:\n",
    "            print(\"Please run this program with a positive even number of processes.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "ad304f60e7ddd2c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task2.py\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T12:28:56.044654Z",
     "start_time": "2025-11-22T12:28:55.844543Z"
    }
   },
   "cell_type": "code",
   "source": "!mpiexec -n 6 python task2.py",
   "id": "d9d6f78e225c457c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2 of 6 on DESKTOP-L6FRMTM computed 2 and received 3\n",
      "Process 4 of 6 on DESKTOP-L6FRMTM computed 4 and received 5\n",
      "\n",
      "Process 3 of 6 on DESKTOP-L6FRMTM computed 3 and received 2\n",
      "\n",
      "Process 5 of 6 on DESKTOP-L6FRMTM computed 5 and received 4\n",
      "\n",
      "\n",
      "Process 0 of 6 on DESKTOP-L6FRMTM computed 0 and received 1\n",
      "Process 1 of 6 on DESKTOP-L6FRMTM computed 1 and received 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Як можемо бачити з цього прикладу, дані попарно відправляються між процесами один одному.\n",
    "\n",
    "Процес 1, відправив процесу 0 значення свого рангу \"1\", а процес 0 в свою чергу, відправив процесу 1 аналогічно - \"0\"\n",
    "\n",
    "**Атрибути функцій обміну (Send / Recv):**\n",
    "\n",
    "У блокуючому парному обміні беруть участь такі параметри:\n",
    "\n",
    "* buf - область памʼяті з даними для передачі або прийому.\n",
    "* count - кількість елементів у буфері.\n",
    "* datatype - MPI-тип одного елемента (MPI_INT, MPI_DOUBLE, масиви NumPy і т.д.).\n",
    "* dest / source - ранг процесу, якому надсилаємо або від якого очікуємо повідомлення.\n",
    "* tag - ціле число для логічної ідентифікації виду повідомлення.\n",
    "* comm - комунікатор (наприклад, MPI_COMM_WORLD).\n",
    "* status (тільки для Recv) - структура, у якій після завершення зберігається фактичний відправник, тег та код завершення.\n",
    "\n",
    "**Аналіз типів даних:**\n",
    "1. MPI не робить автоматичного перетворення типів: тип відправника і одержувача має збігатися.\n",
    "2. count і datatype однозначно визначають обсяг памʼяті, що MPI повинна передати.\n",
    "3. Якщо count = 0, операція дозволена й завершується миттєво.\n",
    "4. Розмір приймального буфера повинен бути не меншим, ніж фактичний розмір отриманих даних - інакше помилка.\n",
    "5. У mpi4py:\n",
    "  * send(obj) - обʼєкт серіалізується, тип визначається автоматично.\n",
    "  * Send([...], MPI.INT) - передаються сирі дані з чітким типом і розміром.\n",
    "6. Типи даних визначають спосіб розбору байтів, тому невідповідність типів призводить до некоректного читання або помилки.\n",
    "\n",
    "**Семантичний аналіз парного блокуючого обміну**\n",
    "\n",
    "1. Операція MPI_Send блокується, поки MPI не гарантує, що буфер можна змінювати (дані або передані, або скопійовані в буфер MPI).\n",
    "2. MPI_Recv блокується, поки дані не будуть повністю отримані і записані в приймальний буфер.\n",
    "3. Відправник та одержувач повинні бути логічно узгоджені: однаковий tag, однаковий datatype, однаковий count, коректно вказані source/dest\n",
    "4. Порушення симетрії веде до дедлоку (наприклад, обидва процеси одночасно викликають Send і жоден не виконує Recv).\n",
    "5. Завершення Send не означає, що одержувач вже отримав повідомлення - лише те, що відправник може використовувати буфер.\n",
    "6. Завершення Recv означає, що дані гарантовано у приймальному буфері.\n",
    "7. Парний блокуючий обмін створює локальну синхронізацію між процесами: один процес не може рухатись далі, доки пара не виконає узгоджену операцію."
   ],
   "id": "e09f029547399209"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Змінимо в програмі порядок виконання функцій для парних рангів, щоб продемострувати дедлок**",
   "id": "5f8db6a8bf22e086"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T12:28:56.059103Z",
     "start_time": "2025-11-22T12:28:56.054421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile task2_deadlock.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "# function to return whether a number of a process is odd or even\n",
    "def odd(number):\n",
    "    if (number % 2) == 0:\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            #number of the process running the code\"\n",
    "    numProcesses = comm.Get_size()  #total number of processes running\"\n",
    "    myHostName = MPI.Get_processor_name()  #machine name running the code\"\n",
    "\n",
    "    # num of processes must be even\n",
    "    if numProcesses > 1 and not odd(numProcesses):\n",
    "        sendValue = id\n",
    "\n",
    "         #odd processes receive from their paired 'neighbor', then send\n",
    "        if odd(id):\n",
    "            receivedValue = comm.recv(source=id - 1)\n",
    "            comm.send(sendValue, dest=id - 1)\n",
    "\n",
    "        #even processes receive from their paired 'neighbor', then send\n",
    "        else:\n",
    "            receivedValue = comm.recv(source=id + 1)\n",
    "            comm.send(sendValue, dest=id + 1)\n",
    "\n",
    "        print(\n",
    "            \"Process {} of {} on {} computed {} and received {}\".format(\n",
    "                id, numProcesses, myHostName, sendValue, receivedValue\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if id == 0:\n",
    "            print(\"Please run this program with a positive even number of processes.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "9de405c0c11948d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task2_deadlock.py\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T12:29:03.139724Z",
     "start_time": "2025-11-22T12:28:56.076329Z"
    }
   },
   "cell_type": "code",
   "source": "!mpiexec -n 6 python task2_deadlock.py",
   "id": "bcc1246995a25e02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Як бачимо процеси зависли - дедлок",
   "id": "37ada9b3a6d96fc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**3. Виконати аналіз інших комунікаційних режимів. Показати зміни в шаблоні для їх реалізації.**",
   "id": "1a1690bf04598ced"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**У MPI існує чотири режими відправки повідомлень. Головна відмінність між ними — це умова завершення функції відправки (коли функція повертає управління програмі)**\n",
    "\n",
    "* Синхронний (Synchronous), ssend - Рукостискання. Функція завершується тільки тоді, коли процес-одержувач розпочав прийом повідомлення (викликав recv). Це гарантує, що обидва процеси досягли точки обміну. Найбезпечніший, але може бути повільнішим через очікування\n",
    "* Буферизований (Buffered), bsend - Через буфер користувача. Повідомлення копіюється у спеціально виділений  буфер, і функція повертається миттєво. Не треба залежати від того, чи готовий одержувач. Ризик: якщо буфер переповниться, виникне помилка.\n",
    "* По готовності (Ready), rsend - Оптимістичний. Можна викликати лише якщо ви впевнені на 100%, що одержувач вже викликав recv. Якщо ні — поведінка не визначена (помилка або краш). Використовується вкрай рідко для оптимізації."
   ],
   "id": "c91a31549407e721"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:03:04.530826Z",
     "start_time": "2025-11-22T13:03:04.524908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile task3.py\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "# Функція перевірки на непарність\n",
    "def odd(number):\n",
    "    return number % 2 != 0\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    name = MPI.Get_processor_name()\n",
    "\n",
    "    # Перевірка, що кількість процесів парна\n",
    "    if size < 2 or odd(size):\n",
    "        if rank == 0:\n",
    "            print(\"Please run this program with a positive even number of processes.\")\n",
    "        exit(0)\n",
    "\n",
    "    # Підготовка даних (використовуємо numpy, як у вашому прикладі на фото)\n",
    "    # rank - це число, яке ми надсилаємо\n",
    "    send_data = np.array([rank], dtype='i')\n",
    "    recv_data = np.array([0], dtype='i')\n",
    "\n",
    "    # Визначаємо сусіда\n",
    "    if odd(rank):\n",
    "        neighbor = rank - 1\n",
    "    else:\n",
    "        neighbor = rank + 1\n",
    "\n",
    "    # === ЛОГІКА ОБМІНУ ===\n",
    "\n",
    "    # Для простоти реалізуємо схему:\n",
    "    # Непарні: ВІДПРАВЛЯЮТЬ всіма способами -> потім ПРИЙМАЮТЬ всіма способами\n",
    "    # Парні:   ПРИЙМАЮТЬ всіма способами   -> потім ВІДПРАВЛЯЮТЬ всіма способами\n",
    "    # Це запобігає дедлокам і дозволяє Rsend працювати коректно (бо Recv вже викликаний).\n",
    "\n",
    "    if odd(rank):\n",
    "        # --- 1. ВІДПРАВКА (Send) ---\n",
    "        # Standard\n",
    "        comm.Send([send_data, MPI.INT], dest=neighbor, tag=0)\n",
    "\n",
    "        # Buffered\n",
    "        buf = bytearray(MPI.BSEND_OVERHEAD + send_data.nbytes)\n",
    "        MPI.Attach_buffer(buf)\n",
    "        comm.Bsend([send_data, MPI.INT], dest=neighbor, tag=1)\n",
    "        MPI.Detach_buffer()\n",
    "\n",
    "        # Synchronous\n",
    "        comm.Ssend([send_data, MPI.INT], dest=neighbor, tag=2)\n",
    "\n",
    "        # Ready (працює, бо парний процес вже чекає на Recv)\n",
    "        comm.Rsend([send_data, MPI.INT], dest=neighbor, tag=3)\n",
    "\n",
    "        print(f\"Process {rank} finished ALL SENDS to {neighbor}\")\n",
    "\n",
    "        # --- 2. ПРИЙОМ (Receive) ---\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=0) # Standard\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=1) # Buffered\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=2) # Sync\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=3) # Ready\n",
    "\n",
    "        print(f\"Process {rank} finished ALL RECVS from {neighbor}. Last value: {recv_data[0]}\")\n",
    "\n",
    "    else:\n",
    "        # --- 1. ПРИЙОМ (Receive) ---\n",
    "        # Парні процеси спочатку слухають, що робить їх готовими до Rsend від сусідів\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=0) # Standard\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=1) # Buffered\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=2) # Sync\n",
    "        comm.Recv([recv_data, MPI.INT], source=neighbor, tag=3) # Ready\n",
    "\n",
    "        print(f\"Process {rank} finished ALL RECVS from {neighbor}. Last value: {recv_data[0]}\")\n",
    "\n",
    "        # --- 2. ВІДПРАВКА (Send) ---\n",
    "        # Standard\n",
    "        comm.Send([send_data, MPI.INT], dest=neighbor, tag=0)\n",
    "\n",
    "        # Buffered\n",
    "        buf = bytearray(MPI.BSEND_OVERHEAD + send_data.nbytes)\n",
    "        MPI.Attach_buffer(buf)\n",
    "        comm.Bsend([send_data, MPI.INT], dest=neighbor, tag=1)\n",
    "        MPI.Detach_buffer()\n",
    "\n",
    "        # Synchronous\n",
    "        comm.Ssend([send_data, MPI.INT], dest=neighbor, tag=2)\n",
    "\n",
    "        # Ready\n",
    "        comm.Rsend([send_data, MPI.INT], dest=neighbor, tag=3)\n",
    "\n",
    "        print(f\"Process {rank} finished ALL SENDS to {neighbor}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "7768fbb394373177",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task3.py\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:03:16.951293Z",
     "start_time": "2025-11-22T13:03:16.644106Z"
    }
   },
   "cell_type": "code",
   "source": "!mpiexec -n 6 python task3.py",
   "id": "ac975ba6f097c6fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1 finished ALL SENDS to 0\n",
      "Process 0 finished ALL RECVS from 1. Last value: 1\n",
      "\n",
      "\n",
      "Process 0 finished ALL SENDS to 1\n",
      "Process 1 finished ALL RECVS from 0. Last value: 0\n",
      "\n",
      "\n",
      "Process 5 finished ALL SENDS to 4\n",
      "Process 4 finished ALL RECVS from 5. Last value: 5\n",
      "\n",
      "\n",
      "Process 4 finished ALL SENDS to 5\n",
      "Process 5 finished ALL RECVS from 4. Last value: 4\n",
      "\n",
      "\n",
      "Process 3 finished ALL SENDS to 2\n",
      "Process 2 finished ALL RECVS from 3. Last value: 3\n",
      "\n",
      "\n",
      "Process 2 finished ALL SENDS to 3\n",
      "Process 3 finished ALL RECVS from 2. Last value: 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
